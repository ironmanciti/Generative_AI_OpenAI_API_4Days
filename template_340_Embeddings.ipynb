{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f780ca-9e08-4017-b4eb-00b7c5eebf35",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "OpenAI의 텍스트 임베딩은 텍스트 문자열의 관련성을 측정합니다. 임베딩은 일반적으로 다음 용도로 사용됩니다.\n",
    "\n",
    "- 두 텍스트 사이의 관련성을 측정하는 데 사용할 수 있는 텍스트의 숫자 표현  \n",
    "- 검색, 클러스터링, 추천, 이상 탐지 및 분류 작업에 유용\n",
    "\n",
    "    - 검색 (쿼리 문자열과의 관련성을 기준으로 결과 순위 지정)  \n",
    "    - 클러스터링 (텍스트 문자열이 유사성을 기준으로 그룹화)  \n",
    "    - 추천 (관련 문자열이 포함된 항목을 추천)  \n",
    "    - 이상 탐지 (관련성이 거의 없는 이상값이 식별되는 경우)  \n",
    "    - 다양성 측정 (유사성 분포를 분석)\n",
    "    - 분류 (텍스트 문자열이 가장 유사한 레이블로 분류)\n",
    "  \n",
    "임베딩은 부동 소수점 숫자의 벡터(목록)입니다. 두 벡터 사이의 거리는 관련성 을 측정합니다. 거리가 작을수록 관련성이 높음을 나타내고, 거리가 멀면 관련성이 낮다는 것을 나타냅니다.  \n",
    "\n",
    "<img src=https://cdn.sanity.io/images/vr8gru94/production/e016bbd4d7d57ff27e261adf1e254d2d3c609aac-2447x849.png width=600 />\n",
    "\n",
    "### 벡터 유사도:\n",
    "\n",
    "이제 두 개의 서로 다른 영화에 대한 두 개의 숫자 목록이 있다고 가정해 보겠습니다. 영화가 비슷한지 어떻게 알 수 있나요? 여기서 벡터 유사도가 측정됩니다.\n",
    "\n",
    "요약하면,\n",
    "\n",
    "- **임베딩**은 컴퓨터가 이해할 수 있는 특수 숫자 코드로 영화 등의 자세한 설명을 작성하는 것과 같습니다.\n",
    "- **벡터 유사도**는 두 영화와 같이 두 숫자 집합이 나타내는 항목이 서로 얼마나 유사한지 알 수 있습니다.\n",
    "\n",
    "\n",
    "<img src=https://cdn.sanity.io/images/vr8gru94/production/5a5ba7e0971f7b6dc4697732fa8adc59a46b6d8d-338x357.png width=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a8ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40455a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ce68fd-4374-4f99-8118-0606ca58b9cb",
   "metadata": {},
   "source": [
    "## API 사용 방법\n",
    "\n",
    "- 기본적으로 임베딩 벡터의 길이는 text-embedding-3-small의 경우 1536이고 text-embedding-3-large의 경우 3072입니다. 차원 매개변수를 전달하면 임베딩이 개념을 나타내는 속성을 잃지 않고  임베딩의 차원을 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8cf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 임베딩 생성 요청\n",
    "# 응답에서 임베딩 vector의 처음 10개 차원을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ad76f-004e-450f-8827-3897510512ea",
   "metadata": {},
   "source": [
    "## Amazon 고급 음식 리뷰를 이용한 Text Search\n",
    "\n",
    "데이터 세트에는 2012년 10월까지 Amazon 사용자가 남긴 총 568,454개의 음식 리뷰가 포함되어 있습니다. 이 중 가장 최근 리뷰 1,000개로 구성된 이 데이터 세트의 subset을 사용합니다. 리뷰는 영어로 작성되며 긍정적이거나 부정적입니다. 각 리뷰에는 ProductId, UserId, 점수, 리뷰 제목(요약) 및 리뷰 본문(텍스트)이 있습니다.\n",
    "\n",
    "리뷰 요약과 리뷰 텍스트를 하나의 결합 텍스트로 결합합니다. 모델은 이 결합된 텍스트를 인코딩하고 단일 벡터 임베딩을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fce028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터세트 로드 및 검사\n",
    "# input_datapath = \"data/fine_food_reviews_1k.csv\"  # 공간을 절약하기 위해 사전 필터링된 데이터세트를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0844047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a9d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3244638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 너무 길어서 포함할 수 없는 리뷰는 생략합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58b601-9440-47c7-b232-54c0264e24ef",
   "metadata": {},
   "source": [
    "-  임베딩을 나중에 재사용할 수 있도록 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd545049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model=embedding_model, **kwargs):\n",
    "    # 성능에 부정적인 영향을 줄 수 있는 개행 문자를 space로 바꿉니다.\n",
    "    # 클라이언트를 사용하여 텍스트의 임베딩을 생성합니다.\n",
    "    # 임베딩 결과를 반환합니다.\n",
    "def cosine_similarity(a, b):\n",
    "    # 두 벡터 간의 코사인 유사도를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83616313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수분(5-6분) 정도 소요됩니다. 시간 절약을 위해 생략하고 기 저장된 파일 사용.\n",
    "# df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, model=embedding_model))\n",
    "# df.to_csv(\"output/fine_food_reviews_with_embeddings_1k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854399e-2d7f-4ac3-8746-6d87aed3af4a",
   "metadata": {},
   "source": [
    "- 가장 관련성이 높은 문서를 검색하기 위해 쿼리의 임베딩 벡터와 각 문서 간의 코사인 유사성을 사용하고 가장 높은 점수를 받은 문서를 반환합니다.\n",
    "- 'delicious beans'라는 제품 설명과 유사한 상위 3개의 리뷰를 검색하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 제품 설명에 대한 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 각 임베딩과 제품 설명 임베딩 간의 유사도 계산\n",
    "# 유사도를 기준으로 내림차순 정렬하고 상위 n개의 리뷰 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4169460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
