{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cb2a64-fb8f-40de-a2f4-33960756b3d4",
   "metadata": {},
   "source": [
    "# Prompt Examples\n",
    "\n",
    "- https://platform.openai.com/docs/guides/function-calling 참조\n",
    "\n",
    "- API 호출에서 함수를 설명하고 모델이 하나 이상의 함수를 호출하기 위한 인수를 포함하는 JSON 객체를 출력하도록 지능적으로 선택할 수 있습니다. ***Chat Completions API는 함수를 호출하지 않습니다.** 대신 모델은 코드에서 **함수를 호출하는 데 사용할 수 있는 JSON을 생성**합니다. \n",
    "\n",
    "최신 모델( gpt-4o, gpt-4-turbo, 및 gpt-4o-mini)은 함수를 호출해야 하는 시점(입력에 따라 다름)을 감지하고 이전 모델보다 함수 시그니처를 더 면밀히 준수하는 JSON으로 응답하도록 훈련되었습니다. 이 기능에는 잠재적인 위험도 따릅니다. 사용자를 대신하여 세상에 영향을 미치는 작업(이메일 보내기, 온라인에 게시하기, 구매하기 등)을 수행하기 전에 사용자 확인 흐름을 빌드하는 것이 좋습니다.\n",
    "\n",
    "### 일반적인 사용 사례\n",
    "함수 호출을 통해 모델에서 구조화된 데이터를 보다 안정적으로 가져올 수 있습니다. 예를 들어, 다음을 수행할 수 있습니다.\n",
    "\n",
    "- 외부 API를 호출하여 질문에 답변하는 도우미를 만듭니다. 예를 들어, 다음과 같은 함수를 정의합니다.  \n",
    "send_email(to: string, body: string) 또는 get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')\n",
    " \n",
    "- 자연어를 API 호출로 변환  \n",
    "예를 들어 \"내 최고 고객은 누구입니까?\"를 get_customers(min_revenue: int, created_before: string, limit: int)로 convert 하고 내부 API를 호출합니다.\n",
    "\n",
    "- 텍스트에서 구조화된 데이터 추출  \n",
    "extract_data(name: string, birthday: string) 라는 함수를 정의하거나 sql_query(query: string) 라는 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab83658-5530-404c-be6b-0125a375fd2e",
   "metadata": {},
   "source": [
    "함수 호출의 기본적인 단계 순서는 다음과 같습니다.\n",
    "\n",
    "1. 사용자 쿼리와 functions 매개변수 에 정의된 함수 집합으로 모델을 호출합니다.  \n",
    "2. 모델은 하나 이상의 함수를 호출하도록 선택할 수 있습니다. 그럴 경우, 콘텐츠는 사용자 지정 스키마를 준수하는 문자열화된 JSON 객체가 됩니다(참고: 모델은 매개변수를 혼동할 수 있음).  \n",
    "3. 코드에서 문자열을 JSON으로 구문 분석하고, 제공된 인수가 있으면 해당 인수로 함수를 호출합니다.  \n",
    "4. 함수 응답을 새 메시지로 추가하여 모델을 다시 호출하고, 모델이 결과를 사용자에게 요약하도록 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a834a08-3d41-4e51-9232-bcaee106de5a",
   "metadata": {},
   "source": [
    "### 함수 호출 동작\r\n",
    "기본적으로 `tool_choice`의 기본 값은 `tool_choice: \"auto\"`입니다. 이는 모델이 함수 호출 여부와 호출할 함수를 결정하도록 합니다.\r\n",
    "\r\n",
    "사용 사례에 따라 기본 동작을 맞춤화하는 세 가지 방법을 제공합니다:\r\n",
    "\r\n",
    "1. 모델이 항상 하나 이상의 함수를 호출하도록 강제하려면, `tool_choice: \"required\"`로 설정할 수 있습니다. 그러면 모델은 호출할 함수(들)를 선택합니다.\r\n",
    "2. 모델이 특정 함수만 호출하도록 강제하려면, `tool_choice: {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`로 설정할 수 있습니다.\r\n",
    "3. 함수 호출을 비활성화하고 모델이 사용자에게 표시할 메시지만 생성하도록 강제하려면, `tool_choice: \"none\"`으로 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989f8b65-992a-4c1c-b196-aa19cfff4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a83b1e3-b3f3-42f4-a73f-7bc62e3eb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "Model = \"gpt-4o-mini-2024-07-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a33842e5-f333-4742-a72e-eba5c0119789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9oauQnn9aC4S7LE7vuvBcR8jYijb9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the current weather for the requested cities:\\n\\n- **San Francisco, CA**: 72°C\\n- **Tokyo, Japan**: 10°C\\n- **Paris, France**: 22°C\\n\\nLet me know if you need any more information!', role='assistant', function_call=None, tool_calls=None))], created=1721845306, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_400f27fa1f', usage=CompletionUsage(completion_tokens=54, prompt_tokens=173, total_tokens=227))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 예제 더미 함수로, 동일한 날씨 정보를 반환하도록 하드 코딩됨\n",
    "# 실제 프로덕션에서는 백엔드 API 또는 외부 API가 될 수 있음\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"주어진 위치의 현재 날씨를 가져옵니다\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "def run_conversation():\n",
    "    # 1단계: 대화와 사용 가능한 함수들을 모델에게 보냅니다\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"주어진 위치의 현재 날씨를 가져옵니다\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"도시와 주를 입력하세요, 예: San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto가 기본 값이지만, 명시적으로 설정합니다\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # 2단계: 모델이 함수를 호출하려고 했는지 확인합니다\n",
    "    if tool_calls:\n",
    "        # 3단계: 함수를 호출합니다\n",
    "        # 참고: JSON 응답이 항상 유효한 것은 아니므로, 오류를 처리할 수 있도록 해야 합니다\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # 이 예제에서는 하나의 함수만 사용되지만, 여러 개의 함수를 사용할 수도 있습니다\n",
    "        messages.append(response_message)  # 어시스턴트의 답변으로 대화를 확장합니다\n",
    "        # 4단계: 각 함수 호출 및 함수 응답에 대한 정보를 모델에 전송합니다\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # 함수 응답으로 대화를 확장합니다\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "        )  # 함수 응답을 볼 수 있는 새로운 응답을 모델로부터 가져옵니다\n",
    "        return second_response\n",
    "        \n",
    "response = run_conversation()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "551cc4f5-80d6-4218-bc56-932cf77b0d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the current weather for the requested cities:\n",
      "\n",
      "- **San Francisco, CA**: 72°C\n",
      "- **Tokyo, Japan**: 10°C\n",
      "- **Paris, France**: 22°C\n",
      "\n",
      "Let me know if you need any more information!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
